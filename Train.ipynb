{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10423908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ad36e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>D:/University/Courses/Capstone/CREMA-D/AudioWA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>D:/University/Courses/Capstone/CREMA-D/AudioWA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>D:/University/Courses/Capstone/CREMA-D/AudioWA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>D:/University/Courses/Capstone/CREMA-D/AudioWA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>D:/University/Courses/Capstone/CREMA-D/AudioWA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0    angry  D:/University/Courses/Capstone/CREMA-D/AudioWA...\n",
       "1  disgust  D:/University/Courses/Capstone/CREMA-D/AudioWA...\n",
       "2     fear  D:/University/Courses/Capstone/CREMA-D/AudioWA...\n",
       "3    happy  D:/University/Courses/Capstone/CREMA-D/AudioWA...\n",
       "4  neutral  D:/University/Courses/Capstone/CREMA-D/AudioWA..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema = r\"D:/University/Courses/Capstone/CREMA-D/AudioWAV/\"\n",
    "\n",
    "directory_list = os.listdir(crema)\n",
    "\n",
    "emotion = []\n",
    "path = []\n",
    "\n",
    "for file in directory_list:\n",
    "    # storing the paths\n",
    "    path.append(crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        emotion.append('neutral')\n",
    "    else:\n",
    "        emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(path, columns=['Path'])\n",
    "crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e9232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of different emotions in the CREMA file\n",
    "\n",
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(crema_df.Emotions)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ecba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for creating a waveplot\n",
    "\n",
    "def create_waveplot(data, sr, emo):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title('Waveplot for audio with {} emotion'.format(emo), size=15)\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    plt.show()\n",
    "    \n",
    "#Function for creating Spectrogram    \n",
    "\n",
    "def create_spectrogram(data, sr, emo):\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title('Spectrogram for audio with {} emotion'.format(emo), size=15)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n",
    "    plt.colorbar()\n",
    "\n",
    "def plot_wp_s(emo):\n",
    "    path_temp = np.array(crema_df.Path[crema_df.Emotions==emo])[1]\n",
    "    data, sampling_rate = librosa.load(path_temp)\n",
    "    create_waveplot(data, sampling_rate, emo)\n",
    "    create_spectrogram(data, sampling_rate, emo)\n",
    "    Audio(path_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb00319",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wp_s('fear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc8315",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wp_s('angry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wp_s('sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a038e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wp_s('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wp_s('disgust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567015d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wp_s('neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c3b2f",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ef087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different augmentation techniques\n",
    "\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    print(shift_range)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "# taking any example and checking for techniques.\n",
    "path_ex = np.array(crema_df.Path)[1]\n",
    "data, sample_rate = librosa.load(path_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5733925",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveshow(y=data, sr=sample_rate)\n",
    "Audio(path_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1848d571",
   "metadata": {},
   "source": [
    "2. Noise Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4358c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = noise(data)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a691b040",
   "metadata": {},
   "source": [
    "3. Stretching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ec29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stretch(data)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb4986",
   "metadata": {},
   "source": [
    "4. Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eace05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = shift(data)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc190ba",
   "metadata": {},
   "source": [
    "5. Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004df283",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pitch(data, sample_rate)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveshow(y=x, sr=sample_rate)\n",
    "Audio(x, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'disgust':0,'happy':1,'sad':2,'neutral':3,'fear':4,'angry':5}\n",
    "\n",
    "Crema_df.replace({'Emotions':labels},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2abef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mfcc=13\n",
    "\n",
    "n_fft=2048\n",
    "\n",
    "hop_length=512\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "data = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": [],\n",
    "        \"zcr\": [],\n",
    "        \"chroma_stft\": [],\n",
    "        \"rms\": [],\n",
    "        \"melspectrogram\": []\n",
    "    }\n",
    "\n",
    "for i in range(7442):\n",
    "    data['labels'].append(Crema_df.iloc[i,0])\n",
    "    signal, sample_rate = librosa.load(Crema_df.iloc[i,1], sr=SAMPLE_RATE)\n",
    "    mfcc = librosa.feature.mfcc(signal, sample_rate, n_mfcc=13, n_fft=2048, hop_length=512)\n",
    "    mfcc = mfcc.T\n",
    "    data[\"mfcc\"].append(np.asarray(mfcc))\n",
    "    zcr = librosa.feature.zero_crossing_rate(signal, sample_rate)\n",
    "    zcr = zcr.T\n",
    "    data[\"zcr\"].append(np.asarray(zcr))\n",
    "    chroma_stft = librosa.feature.chroma_stft(signal, sample_rate)\n",
    "    chroma_stft = chroma_stft.T\n",
    "    data[\"chroma_stft\"].append(np.asarray(chroma_stft))\n",
    "    rms = librosa.feature.rms(signal, sample_rate)\n",
    "    rms = rms.T\n",
    "    data[\"rms\"].append(np.asarray(rms))\n",
    "    melspectrogram = librosa.feature.melspectrogram(signal, sample_rate)\n",
    "    melspectrogram = melspectrogram.T\n",
    "    data[\"melspectrogram\"].append(np.asarray(melspectrogram))\n",
    "\n",
    "    if i%500==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e949173",
   "metadata": {},
   "source": [
    "## Saving Feature Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e466c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_dict_all.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f41a120",
   "metadata": {},
   "source": [
    "## Load Feature Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb03896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_dict_all.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(loaded_data[\"melspectrogram\"])\n",
    "y = np.asarray(loaded_data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd49159",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2f2a0",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 123)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state =123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c47e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,y_train.shape,X_validation.shape,y_validation.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbe875",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(LSTM(64)) \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "\n",
    "input_shape = (None,12)\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# compile model\n",
    "\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience = 10)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=512, epochs=150, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0706cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baef3d1",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd68940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model_chroma_stft.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_chroma_stft.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847798bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")\n",
    "\n",
    "epochs = [i for i in range(35)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss'] \n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1589b",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model_melspec.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_mel_spec = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model_mel_spec.load_weights(\"model_melspec.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model_mel_spec.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"Accuracy of our model on test data : \" , loaded_model_mel_spec.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9baecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_melspec=loaded_model_mel_spec.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c11a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_classes_melspec = np.argmax(predict_prob_melspec,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93476d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predict_classes_melspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "score = metrics.accuracy_score(y_test, predict_classes_melspec)*100\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predict_classes_melspec)\n",
    "plot_confusion_matrix(cm, classes=['0', '1', '2', '3', '4', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc1b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predict_classes_melspec, labels=[0, 1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8ec4e",
   "metadata": {},
   "source": [
    "## Appendix - CNN Model [ALTERNATIVE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351bc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(None, 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(tf.keras.layers.GlobalMaxPool1D())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
